# Analyse de Sentiment

## 1. Pr√©sentation G√©n√©rale

### 1.1. Objectif

La soci√©t√© *Air Paradis* souhaite d√©tecter les √©ventuels *Bad Buzz* afin d'anticiper ou de pr√©parer une r√©ponse rapide.
Dans ce cadre, nous d√©veloppons un outil permettant d'analyser des tweets et de pr√©dire leur sentiment (positif ou n√©gatif).

### 1.2. Domaine d'√©tude

Nous utilisons des r√©seaux de neurones profonds, sp√©cialement dans le domaine du *Natural Language Processing* (NLP).
Les donn√©es sont compos√©es de tweets en langue anglaise.

#### Exemples de tweets classifiables

- **"Great day out"** (*Super journ√©e.*) ‚Üí Sentiment **positif**
- **"Goodness I am tired... Ugh lack of sleep is so bad for me."** (*Mon dieu, je suis √©puis√©... Le manque de sommeil est mauvais pour moi.*) ‚Üí Sentiment **n√©gatif**
- **"@TheSilentCoyote what about the podcast?"** ‚Üí Difficile √† classifier

Les d√©fis de cette classification incluent :
- **Orthographe et syntaxe approximatives**
- **Implicite** (humour, ironie, sarcasme)
- **Analyse du contexte**

### 1.3. Principes et √©valuation

Le jeu de donn√©es est divis√© en deux :
- **Jeu d'entra√Ænement** pour configurer nos mod√®les
- **Jeu de test** pour √©valuer les performances

L'√©quilibre parfait entre tweets positifs et n√©gatifs garantit une √©valuation fiable.

Nous explorons plusieurs approches et comparons les mod√®les selon plusieurs m√©triques :
- **Pr√©cision**, **Recall**, **Sp√©cificit√©**, **Accuracy**, **F1-score**
- **Courbe ROC & AUC**, **Matrice de confusion**
- **Temps d'entra√Ænement**

### 1.4. Pr√©paration des donn√©es

Les tweets subissent une **tokenisation** avant d'√™tre transform√©s de trois mani√®res :
- Texte brut (*Raw*)
- **Lemmatisation**
- **Stemmatisation**

### 1.5. Mod√©lisation

Trois approches sont test√©es :
1. **Mod√®le simple** : Algorithmes de *Machine Learning* rapide
2. **Mod√®le avanc√©** : *Deep Learning* avec *Word Embedding*
3. **Mod√®le BERT** : *Transfer Learning*

---

## 2. Analyse Exploratoire

Les donn√©es sont issues de [Sentiment140 (Kaggle)](https://www.kaggle.com/datasets/kazanova/sentiment140).
Elles comprennent 1,6 million de tweets avec 6 caract√©ristiques, mais nous retenons seulement :
- **Text** : Contenu du tweet
- **Target** : Sentiment (0 = n√©gatif, 4 = positif)

#### R√©partition des sentiments

**Variable cible parfaitement √©quilibr√©e** :
- 800 000 tweets positifs
- 800 000 tweets n√©gatifs

---

## 3. Pr√©traitement (*Preprocessing*)

### 3.1. Substitutions appliqu√©es aux tweets

1. Remplacement des **URLs** par `'<url>'`
2. Remplacement des **@usernames** par `'<user>'`
3. R√©duction des **lettres r√©p√©t√©es** (`'Heyyyy' ‚Üí 'Heyy'`)
4. Remplacement des **√©mojis** par des √©quivalents textuels
5. Expansion des **contractions** (`"can't" ‚Üí "cannot"`)
6. Suppression des **caract√®res sp√©ciaux**

### 3.2. Tokenisation

Utilisation de `word_tokenize` (NLTK) suivie de lemmatisation/stemmatisation.

---

## 4. Mod√©lisation

Nous utilisons un √©chantillon de 200 000 tweets (donn√©es √©quilibr√©es).

### 4.1. Mod√®le simple (*Machine Learning*)

**Algorithmes test√©s :**
- **R√©gression Logistique**
- **Naive Bayes**
- **Support Vector Classifier (SVC)**

#### R√©sultats

| Mod√®le | Accuracy (sans preprocessing) |
|---------|--------------------------|
| Logistic Regression | **80.28%** |
| SVC | 79.69% |
| Naive Bayes | 78.58% |

Mod√®le retenu : **R√©gression Logistique (C=2, 1000 it√©rations)**

**Performances :**
- **Accuracy** : 80.28%
- **ROC AUC** : 88.38%
- **Temps d'entra√Ænement** : 30 sec

---

### 4.2. Mod√®le avanc√© (*Deep Learning*)

**Word Embeddings test√©s :**
- **FastText**, **GloVe**, **Word2Vec**

**Avec et sans LSTM**

#### R√©sultats

| Embedding | Sans LSTM | Avec LSTM |
|-----------|----------|-----------|
| **GloVe** | 78.16% | **79.30%** |
| Word2Vec | 75.51% | 76.63% |
| FastText | 77.56% | 78.98% |

**Mod√®le retenu :** GloVe + LSTM

---

### 4.3. Mod√®le BERT (*Transfer Learning*)

Utilisation de **bert-base-uncased** avec *fine-tuning*.

#### R√©sultats

| Mod√®le | Accuracy | ROC AUC |
|---------|---------|---------|
| **BERT** | **84.25%** | **90.21%** |

---

## Conclusion

- **Le mod√®le BERT offre les meilleures performances**.
- **LSTM + GloVe est une alternative valable** si les ressources sont limit√©es.
- **Les mod√®les classiques (Logistic Regression) sont rapides mais moins pr√©cis**.

---

Ce projet montre l'importance du choix de mod√®le et du pr√©traitement pour l'analyse de sentiment ! üöÄ

